{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Assignment_Big_Data_Mining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM12sb-kgn7O"
      },
      "source": [
        "# **Final Assignment - Big Data Mining 2021**\n",
        "\n",
        "Shira Esudri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcDd4IN4mjai"
      },
      "source": [
        "## **A general description of the assignment**\n",
        "\n",
        "In this assignment, we will read and analyze a large dataset from the Amazon Web Service (AWS) Simple Storage Service (S3). <br>\n",
        "The data we will work with is the *Amazon Customer Reviews Dataset*, that contains textual data of customer reviews, in addition to the rating of each product (on a scale of $1$ to $5$) and additional features. \n",
        "\n",
        "The four parts of the assignments are: \n",
        "*    **Part 1:** Connecting to the service and reading data\n",
        "*    **Part 2:** Data preprocessing and feature engineering \n",
        "*    **Part 3:** Fitting a classification model to a large dataset \n",
        "*    **Part 4:** Fitting streaming data using Stochastic Gradient Descent\n",
        "\n",
        "#### **About the Data: Amazon Customer Reviews Dataset**  \n",
        "The dataset contains over $130$ million customer reviews vailable to researchers as part of this release, collected from from 1995 until 2015. \n",
        "The data is available in tab-delimited compressed (zipped) `tsv` files in the `amazon-reviews-pds` S3 `bucket` (see later). <br>\n",
        "Each line in the data files corresponds to an individual review (tab delimited).Bucket: `amazon-reviews-pds`. Tab Separated Values Data pre-fix: `tsv`.\n",
        "The dataset is divided into different product categories, identified by `keys`. For example, a category for `cameras` is represented by the key: <br>\n",
        " `amazon-reviews-pds/tsv/amazon_reviews_us_Camera_v1_00.tsv.gz`  \n",
        "\n",
        "\n",
        "#### **What is Amazon Web Services S3?**  \n",
        "\n",
        "Amazon Simple Storage Service (Amazon S3, similar to Google Cloud Storage, Azure Blob Storage, ...) is storage for the Internet. It is designed to make web-scale data transfer, reading, writing and computing easier.\n",
        "Amazon S3 provides a simple interface that gives any developer access to the same highly scalable, reliable, fast, and inexpensive data storage infrastructure using code (for example in `python`). <br>\n",
        "However, the S3 file system is not typical, and is built around a key-value/object mapping (key is the location, object is the content and meta data of the file). \n",
        "\n",
        "These key-values are stored in \"folders\" called `buckets`. Buckets are the fundamental containers in Amazon S3 for data storage, and contain `objects` (files). We can store an unlimited amount of data in a bucket, where each object can contain up to 5 TB of data. Each object is stored and retrieved using a unique developer-assigned key.\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYrG2NEVlgDb"
      },
      "source": [
        "%%capture\n",
        "# Installing libraries\n",
        "%pip install boto3\n",
        "!pip3 install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT-DJ-8CktLo"
      },
      "source": [
        "%%capture\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Importing the AWS module. Allows also to work with and read from zipped files.\n",
        "import boto3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Useful text-preprocessing commands\n",
        "from flair.models import TextClassifier\n",
        "from flair.data import Sentence\n",
        "classifier = TextClassifier.load('sentiment-fast') # building sentiment features\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Useful machine-learning commands\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt  # for plotting\n",
        "\n",
        "import math\n",
        "from math import e\n",
        "from math import log\n",
        "# tic and toc functions for measuring time \n",
        "def tic():\n",
        "    import time\n",
        "    global startTime_for_tictoc\n",
        "    startTime_for_tictoc = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NLUfidTiMkg"
      },
      "source": [
        "### **Part 1: Connecting to Amazon Web Server and reading data using boto3**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_agDNd2kfL5"
      },
      "source": [
        "In this section we will get familiar with the AWS S3 cloud storage using API modules. We will create a connection to the cloud storage and access the data.  \n",
        "Specifically, we will use the popular `boto3` AWS library for python to connect to the `amazon-reviews-pds` bucket. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHpR9jkDEYPv"
      },
      "source": [
        "**1.(a) [3 pt]** Using `boto3`'s method called `resource`, run the code below create a connection to AWS S3 named `s3conn`, with your `aws_access_key_id` and `aws_secret_access_key`. \n",
        "\n",
        "Add a line defining a variable called `reviews` that points the `s3conn` conncetion to Amazon's `amazon-reviews-pds` data using the `Bucket` method of `boto3`.  Print the `reviews` variable to verify that it represents the `Bucket` with the `amazon-reviews-pds` dataset. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnUMhmEUM4o5"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEqn2axHANhG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59d6fbd-5a09-40c9-b915-2e8f758bcd35"
      },
      "source": [
        "# If you have an AWS account, replace these with your key-id and access key:\n",
        "akid = 'AKIA5SWU2IND3QS4UA5S' \n",
        "sak = '9CDABiddu52jA6ROVwUMZSJV8ydpGJuNrLQJ4wdz'\n",
        "\n",
        "# Using boto3's resource method, create a connection to AWS S3 \n",
        "s3conn = boto3.resource(\n",
        "    's3',\n",
        "    aws_access_key_id = akid,\n",
        "    aws_secret_access_key = sak\n",
        ")\n",
        "\n",
        "#define a variable called reviews\n",
        "reviews = s3conn.Bucket(\"amazon-reviews-pds\")\n",
        "print(reviews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s3.Bucket(name='amazon-reviews-pds')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM1qLZIxzHvI"
      },
      "source": [
        "I define and print a variable called reviews, The variable points the s3conn conncetion to Amazon's amazon-reviews-pds data using the Bucket method of boto3. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_RC1tjAEppH"
      },
      "source": [
        "**1.(b) [6 pt]** \n",
        "We are only interested in the data within the `tsv` (tab separated values) parent-key (\"folder\"):\n",
        "\n",
        "*   Run the code-cell below to get all the `keys` of the files within the `tsv` parent-key and their respected file size into a dedicated list.  \n",
        "Each key should contain the name of the `object` and the size of the `object` in bytes.\n",
        "*   Filter the keys to include only `tsv` objects containing reviews, and only from the `us`.\n",
        "*   Print the first $15$ elements of the filtered keys list. \n",
        " In addition, print  the total size in GB (rounded to 3 dec. place) of all the objects of type `tsv` (zipped).   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBzGsaELL9Kj"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avplr30zzgpt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "7fea69bf-fb9f-4bcd-fc41-00316b9b70d6"
      },
      "source": [
        "keys_list = []\n",
        "for my_bucket_object in reviews.objects.all():\n",
        "    keys_list.append([my_bucket_object.key,my_bucket_object.size])\n",
        "\n",
        "#Filter the keys to include only tsv objects containing reviews, and only from the us\n",
        "\n",
        "filter_keys = [] #create an empty list \n",
        "for obj in keys_list: #for loop on the given list\n",
        "  if obj[0].endswith('tsv.gz'):\n",
        "    if 'us' in obj[0]: #fillter accorting the Q:\n",
        "      filter_keys.append(obj) #append to the results list\n",
        "\n",
        "#Print the first 15 elements of the filtered keys list\n",
        "display(filter_keys[0:15])\n",
        "\n",
        "#print the total size in GB \n",
        "sum_ = 0 #counter to sum the total size in GB\n",
        "for i in range(len(filter_keys)):\n",
        "  sum_ = sum_ + filter_keys[i][1]\n",
        "sum_GB = sum_/10**9 #in terms of GB\n",
        "print(\"The total size in GB:\", round(sum_GB,3)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[['tsv/amazon_reviews_us_Apparel_v1_00.tsv.gz', 648641286],\n",
              " ['tsv/amazon_reviews_us_Automotive_v1_00.tsv.gz', 582145299],\n",
              " ['tsv/amazon_reviews_us_Baby_v1_00.tsv.gz', 357392893],\n",
              " ['tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz', 914070021],\n",
              " ['tsv/amazon_reviews_us_Books_v1_00.tsv.gz', 2740337188],\n",
              " ['tsv/amazon_reviews_us_Books_v1_01.tsv.gz', 2692708591],\n",
              " ['tsv/amazon_reviews_us_Books_v1_02.tsv.gz', 1329539135],\n",
              " ['tsv/amazon_reviews_us_Camera_v1_00.tsv.gz', 442653086],\n",
              " ['tsv/amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tsv.gz', 2689739299],\n",
              " ['tsv/amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz', 1294879074],\n",
              " ['tsv/amazon_reviews_us_Digital_Music_Purchase_v1_00.tsv.gz', 253570168],\n",
              " ['tsv/amazon_reviews_us_Digital_Software_v1_00.tsv.gz', 18997559],\n",
              " ['tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz', 506979922],\n",
              " ['tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz', 27442648],\n",
              " ['tsv/amazon_reviews_us_Electronics_v1_00.tsv.gz', 698828243]]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total size in GB: 32.377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjiXUxQmzPAA"
      },
      "source": [
        "First i created an empty results list, run a loop and fillter the keys to include only tsv objects, and only from the us containing reviews. To filter I use the \"endwith\" function and check if the string \"us\" is in each string. Then i Print the first 15 elements of the filtered keys list.\n",
        "\n",
        "Next i calculated the total size in GB by running in for loop over, sum the size in the filter list and then divide the sum by 10^9 to make the results in term of GB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rIT4Pnvn2tb"
      },
      "source": [
        "**1.(c) [6 pt]** Using the output of **1.(b)**, create a `pandas` dataframe named `file_categories_df` with the following columns:   \n",
        "<!-- [,,sizeGB] the size of each file: -->\n",
        "\n",
        "*   `category`: the file's (object's) category, parsed from the key string (without unnecessary characters). If there are multiple categories with the same name, use `_00, _01` ... suffixes for different versions\n",
        "*   `size`:  the size in bytes of the file\n",
        "*   `sizeGB`: the size in GB of the file  \n",
        "*   `estSizeGB`: the estimated size in GB of the `uncompressed` file, assuming the gzip compresses a file to size of around `30%` of the original size. \n",
        "    \n",
        "For example, one row of the table should be: <br>\n",
        "`Digital_Software, 18997559, 0.017693, 0.05898`\n",
        "\n",
        "Show the top-10 rows of the created data-frame using the `head` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6a1jCnNMwrq"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxu4WV_ZzVuc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "79c26722-d9d7-4b82-858e-e87034801a49"
      },
      "source": [
        "#creat a list for the category names\n",
        "categor_list = []\n",
        "for i in range(len(filter_keys)):\n",
        "  categor_list.append(filter_keys[i][0][22:-13]) #remove unnecessary characters\n",
        "\n",
        "#add the 00, 01..\n",
        "for i in range(len(categor_list)-1):\n",
        "  if categor_list[i] == categor_list[i+1] and categor_list[i+1] == categor_list[i+2]: #check if  identical\n",
        "      categor_list[i] = categor_list[i]+\"_00\"\n",
        "      categor_list[i+1] = categor_list[i][:-3]+\"_01\"\n",
        "      categor_list[i+2] = categor_list[i+1][:-3]+\"_02\"\n",
        "  if categor_list[i] == categor_list[i+1]:\n",
        "    categor_list[i] = categor_list[i]+\"_00\"\n",
        "    categor_list[i+1] = categor_list[i][:-3]+\"_01\"\n",
        "\n",
        "#creat pandas dataframe\n",
        "file_categories_df = pd.DataFrame(categor_list,columns=[\"category\"])\n",
        "file_categories_df[\"size\"] = pd.DataFrame(filter_keys)[1] #the size in bytes\n",
        "file_categories_df[\"sizeGB\"] = pd.DataFrame(filter_keys)[1]/10**9 #the size in GB\n",
        "file_categories_df[\"estSizeGB\"] = (pd.DataFrame(filter_keys)[1]/10**9)*(100/30) #the estimated size in GB\n",
        "\n",
        "file_categories_df.head(10) #show results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>size</th>\n",
              "      <th>sizeGB</th>\n",
              "      <th>estSizeGB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Apparel</td>\n",
              "      <td>648641286</td>\n",
              "      <td>0.648641</td>\n",
              "      <td>2.162138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Automotive</td>\n",
              "      <td>582145299</td>\n",
              "      <td>0.582145</td>\n",
              "      <td>1.940484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Baby</td>\n",
              "      <td>357392893</td>\n",
              "      <td>0.357393</td>\n",
              "      <td>1.191310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Beauty</td>\n",
              "      <td>914070021</td>\n",
              "      <td>0.914070</td>\n",
              "      <td>3.046900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Books_00</td>\n",
              "      <td>2740337188</td>\n",
              "      <td>2.740337</td>\n",
              "      <td>9.134457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Books_01</td>\n",
              "      <td>2692708591</td>\n",
              "      <td>2.692709</td>\n",
              "      <td>8.975695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Books_02</td>\n",
              "      <td>1329539135</td>\n",
              "      <td>1.329539</td>\n",
              "      <td>4.431797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Camera</td>\n",
              "      <td>442653086</td>\n",
              "      <td>0.442653</td>\n",
              "      <td>1.475510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Digital_Ebook_Purchase_00</td>\n",
              "      <td>2689739299</td>\n",
              "      <td>2.689739</td>\n",
              "      <td>8.965798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Digital_Ebook_Purchase_01</td>\n",
              "      <td>1294879074</td>\n",
              "      <td>1.294879</td>\n",
              "      <td>4.316264</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    category        size    sizeGB  estSizeGB\n",
              "0                    Apparel   648641286  0.648641   2.162138\n",
              "1                 Automotive   582145299  0.582145   1.940484\n",
              "2                       Baby   357392893  0.357393   1.191310\n",
              "3                     Beauty   914070021  0.914070   3.046900\n",
              "4                   Books_00  2740337188  2.740337   9.134457\n",
              "5                   Books_01  2692708591  2.692709   8.975695\n",
              "6                   Books_02  1329539135  1.329539   4.431797\n",
              "7                     Camera   442653086  0.442653   1.475510\n",
              "8  Digital_Ebook_Purchase_00  2689739299  2.689739   8.965798\n",
              "9  Digital_Ebook_Purchase_01  1294879074  1.294879   4.316264"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmsQC1LVzWIV"
      },
      "source": [
        "To create the list of categories, I created an empty category list. I run in for loop over the categories list from the previous section and removed the unnecessary characters of the strings (by stirngs operations). \n",
        "\n",
        "After that I checked if there are identical categoriess. If so I added numbers 00, 01, 02 at the end as required. next I created a new data frame which has four columns: Category, size, sizeGB and estimated size GB. Finally I showed the first 10 categories as requiredby using Panda's head function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u1crB4VFNRt"
      },
      "source": [
        "\n",
        "**1.(d) [6 pt]** **Reading the Data:**    \n",
        "*   Run the code cell below using the `download_file` method for the `bucket` of `s3conn`, to download the file of one of the six *smallest* categories (size < `30MB`) into the colab/local file-system, and read the entire file into a dataframe.\n",
        "\n",
        "*   Read the entire data from the category into a pandas dataframe called `df` \n",
        "and print the number of rows (data points) and columns (features). \n",
        "\n",
        "*   Compute and print the average size in bytes of each data point (an amazon product review). \n",
        "Use this number and the total size computed in **1.(b)** to estimate the total number of reviews in the entire dataset over all categories. \n",
        "How close is it to $130$ million? explain what can cause the difference in numbers.\n",
        "\n",
        "*   Apply `df.head(5)` to view the start of the data-frame.\n",
        "\n",
        "\n",
        "**Note:** during code development, it is allowed here and in other sub-questions (and even recommended) to limit the size of what we load into memory. However, for submission, the full files/requested data sizes should be used. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aUXC1TMOId1"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NULUjpvynGMf"
      },
      "source": [
        "%%capture\n",
        "print('file to read/stream: ', filter_keys[13][0]) # downloading: Digital_Video_Games. Modify to download a different category\n",
        "fileToStream = filter_keys[13][0]\n",
        "# Reading the file (may take time?)\n",
        "s3conn.Bucket('amazon-reviews-pds').download_file(fileToStream, 'tmp.gz')\n",
        "% ls /content/ -lah\n",
        "\n",
        "with gzip.open('/content/tmp.gz', 'rb') as f_in:\n",
        "    tmp = f_in.readlines() # Reading lines into a python object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjIQdIuuoIBv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "7a604d5b-1a64-4ba8-cfdd-a465672460cc"
      },
      "source": [
        "#1.Read the entire data and Preparations\n",
        "lst = [i.decode('utf-8') for i in tmp] #use decode to remove part of a string\n",
        "df = pd.DataFrame([i.split('\\t') for i in lst],columns= lst[0].split('\\t')) #split the tmp to create data frame\n",
        "df = df.drop(labels=[0], axis=0) #drop the first row\n",
        "df[\"review_date\\n\"] = [df[\"review_date\\n\"].iloc[i][:-2] for i in range(len(df[\"review_date\\n\"])) if df[\"review_date\\n\"].iloc[i].endswith('\\n') ] # remove \\n\n",
        "df = df.rename(columns = {'review_date\\n': 'review_date'})\n",
        "\n",
        "#print the number of rows and columns \n",
        "shape = df.shape \n",
        "print(\"Df Shape ={}\\nData Points = {}\\nFeatures = {}\".format(shape, shape[0], shape[1])) \n",
        "\n",
        "#2.Compute and print the average size in bytes of each data point \n",
        "avg_dat_point_size = file_categories_df[\"size\"].iloc[13]/len(df[\"marketplace\"]) \n",
        "print(\"The average size in bytes of each data point: \", round(avg_dat_point_size,3)) \n",
        "\n",
        "#Use this number and the total size computed in 1.(b) to estimate the total number of reviews in the entire dataset over all categories\n",
        "#compute the estimation\n",
        "esti_tot_rev = file_categories_df[\"size\"].sum()/avg_dat_point_size \n",
        "print(\"The estimate total number of reviews in the entire dataset over all categories: \", round(esti_tot_rev,3)) \n",
        "\n",
        "#3.Apply df.head(5) to view the start of the data-fram\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Df Shape =(145431, 15)\n",
            "Data Points = 145431\n",
            "Features = 15\n",
            "The average size in bytes of each data point:  188.699\n",
            "The estimate total number of reviews in the entire dataset over all categories:  171581922.309\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>21269168</td>\n",
              "      <td>RSH1OZ87OYK92</td>\n",
              "      <td>B013PURRZW</td>\n",
              "      <td>603406193</td>\n",
              "      <td>Madden NFL 16 - Xbox One Digital Code</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>A slight improvement from last year.</td>\n",
              "      <td>I keep buying madden every year hoping they ge...</td>\n",
              "      <td>2015-08-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>133437</td>\n",
              "      <td>R1WFOQ3N9BO65I</td>\n",
              "      <td>B00F4CEHNK</td>\n",
              "      <td>341969535</td>\n",
              "      <td>Xbox Live Gift Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome</td>\n",
              "      <td>2015-08-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>45765011</td>\n",
              "      <td>R3YOOS71KM5M9</td>\n",
              "      <td>B00DNHLFQA</td>\n",
              "      <td>951665344</td>\n",
              "      <td>Command &amp; Conquer The Ultimate Collection [Ins...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Hail to the great Yuri!</td>\n",
              "      <td>If you are prepping for the end of the world t...</td>\n",
              "      <td>2015-08-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>113118</td>\n",
              "      <td>R3R14UATT3OUFU</td>\n",
              "      <td>B004RMK5QG</td>\n",
              "      <td>395682204</td>\n",
              "      <td>Playstation Plus Subscription</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Perfect</td>\n",
              "      <td>2015-08-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>US</td>\n",
              "      <td>22151364</td>\n",
              "      <td>RV2W9SGDNQA2C</td>\n",
              "      <td>B00G9BNLQE</td>\n",
              "      <td>640460561</td>\n",
              "      <td>Saints Row IV - Enter The Dominatrix [Online G...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>2015-08-3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  marketplace  ... review_date\n",
              "1          US  ...   2015-08-3\n",
              "2          US  ...   2015-08-3\n",
              "3          US  ...   2015-08-3\n",
              "4          US  ...   2015-08-3\n",
              "5          US  ...   2015-08-3\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kaiALorziTF"
      },
      "source": [
        "First I did prepreparation for the data. I used the decode function to download part of a string, used the split function when the separation parameter was \\t, and removed unnecessary passages in strings like \\n.\n",
        "Next I turned the list into dataframe as requested and printed out the number of rows and columns in it by using the shape method.\n",
        "\n",
        "Then I Computed and print the average size in bytes of each data point and estimate the total number of reviews in the entire dataset over all categories.To calculate the estimate the total number of reviews, I compute the sum of the  size column in file_categories_df and divide it by the average size in bytes of each data point.\n",
        "In the end, i showed the first five rows of the data as requested.\n",
        "\n",
        "**How close is it to  130  million? explain what can cause the difference in numbers**\n",
        "\n",
        "As you can see the estimate total number of reviews in the entire dataset over all categories is over 130 million. A possible explanation for this could be that the category we are working on (filter_keys [13]: Digital Video Games) is more popular than others and therefore on average there are more reviews about it than about less popular categories.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a9h5Y56uz27"
      },
      "source": [
        "### **Part 2: Data preprocessing and feature engineering**\n",
        "\n",
        "In this part we use the textual data to create predictive features, and preprocess additional features, to prepare the data-frame to be used in training a classifier. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPxcAQUY0Ifz"
      },
      "source": [
        "**2.(a) [7 pt]** Apply the following common text normalization and standardization steps to the `review_body` textual column. It is recommended to use the `nltk` package:\n",
        "     \n",
        "1. Create a new column named `reviews_processed`, and assign it the `review_body` strings, just with all characteres as lower-case letters. All the following transformations should be done on the `reviews_processed` column. \n",
        "2. Split to words using the `word_tokenize` method.\n",
        "3. Keep only alpha-numerical values  (you can use `str.isalpha()`). \n",
        "4. Unite together words with similar meanining using the `WordNetLemmatizer` command.\n",
        "5. Remove non-informative words (stop-words) using the `stopwords` command\n",
        "6. Finally, join back all the tokens (words) to a single string for each row. \n",
        "7. Remove rows with empty strings of `review_body`.      \n",
        "\n",
        "Write first a function that recieves as input a data-frame and modifies it according to the steps below. Then, apply the function to the `df` dataframe. \n",
        "\n",
        "Show the top-10 records using the command `df.reviews_processed.head(10)` once you are done. \n",
        "\n",
        "**Note:** Running the commands for this sub-questions may take a few minutes. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9T1voQAsdTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5dfe94-5836-40f2-d51e-95202533efc5"
      },
      "source": [
        "orig_col_names = df.columns #save of later\n",
        "\n",
        "#create the function\n",
        "def df_function(df,col):\n",
        "\n",
        "  #for section 4+5\n",
        "  lemmatizer =WordNetLemmatizer()\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "\n",
        "#1.Create a new column named reviews_processed\n",
        "  df[col] = df['review_body'].str.lower() \n",
        "\n",
        "#2.Split to words using the word_tokenize method.\n",
        "  df[col] = df[col].apply(word_tokenize)\n",
        "  \n",
        "#3.Keep only alpha-numerical values using isalpha method\n",
        "  res = []\n",
        "  for list in df[col]:\n",
        "    res.append([i for i in list if i.isalpha()])\n",
        "  df[col] = res\n",
        "\n",
        "#4.Unite together words with similar meanining using the WordNetLemmatizer command.\n",
        "  res2 = []\n",
        "  for i in range(len(df[col])):\n",
        "    res2.append(([lemmatizer.lemmatize(word) for word in df[col].iloc[i]]))\n",
        "  df[col] = res2\n",
        "\n",
        "#5.Remove non-informative words using the stopwords command\n",
        "  res3 = []\n",
        "  for i in range(len(df[col])):\n",
        "    res3.append([w for w in df[col].iloc[i] if w not in stop_words])\n",
        "  df[col] = res3  \n",
        "  \n",
        "#6.Join back all the tokens to a single string for each row by ubsing join function\n",
        "  res4 = []\n",
        "  for i in range(len(df[col])):\n",
        "    res4.append(' '.join(df[col].iloc[i]))\n",
        "  df[col] = res4\n",
        "\n",
        "#7.Remove rows with empty strings \n",
        "  df[col].replace('', np.nan, inplace=True)\n",
        "  df.dropna(subset=[col], inplace=True)\n",
        "\n",
        "  return df\n",
        "\n",
        "#apply the function to the df dataframe.\n",
        "df = df_function(df,\"reviews_processed\") \n",
        "\n",
        "#Show the top-10 records using the command df.reviews_processed.head(10)\n",
        "df.reviews_processed.head(10) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     keep buying madden every year hoping get back ...\n",
              "2                                               awesome\n",
              "3     prepping end world one thing installed pc hail...\n",
              "4                                               perfect\n",
              "5                                               awesome\n",
              "6                                               awesome\n",
              "7     like new skill like herbalism camping fun also...\n",
              "8                                                 super\n",
              "9                                 excellent fast secure\n",
              "10                                                   ok\n",
              "Name: reviews_processed, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxhmTZcazpck"
      },
      "source": [
        "In this section I built a function that gets a data frame and a name of a column and makes changes to it as we were asked to do. I tried at every step to work efficiently and use as few two loops as possible. The purpose of the function is to make changes to the texts in it so that we can get information from the data of column.\n",
        "\n",
        "First created a new column named review_processed. \n",
        "Next I separated the string that is in each cell in the word column by word_tokenize, went through all the lists in the column in each list and saved only alpha-numerical values by using the isalpha function.\n",
        "I Unite together words with similar meanining words with similar meanings by the WordNetLemmatizer command, When here too I had to go through every cell in the column for all the words. Then, I downloaded meaningless words by stop-words in the same way, combined in each cell all the words it has into one string using join function, downloaded rows in the data where the NA value appears.\n",
        "Finally showed the first 10 rows of the new column I created"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etxHLWfY9_3Q"
      },
      "source": [
        "**2.(b) [6 pt]** **Sentiment analysis using the `flair` library:** \n",
        "We next want to add *sentiment* features to each review, that use a pre-trained model to predict if the review text is positive or negative. Note that we use this only as a way for defining new predictive features from the text. We will train our actual classifier in **Part 3**.\n",
        "\n",
        "1. *Execute* the cells below with the command: <br> \n",
        " `classifier = TextClassifier.load('sentiment-fast')` <br>\n",
        " to load the a pre-trained text classifier object\n",
        "\n",
        "2. Next, Loop over the first $10$ reviews and for each one \n",
        "apply `flair`'s `Sentence` method on the processed review text, an input the resulting sentence to the `classifier.predict()` method. \n",
        "Print for the first $10$ reviews out both the reviews and their sentiment (`NEGATIVE/POSITIVE` and the sentiment score). Do the generated sentiments represent the text? \n",
        "\n",
        "3. How long does it take to compute the sentiments of `100, 1,000`, and `10,000` datapoints in this manner? (do not print them, but make sure that the sentiments are actually computed). Extrapolate and estimate how long would it take to compute the sentiments over all data points in your category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1damM0KCO3aJ"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-X9TFvq-RrM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f277f1-99c3-4afe-fad7-e2d7f08a6453"
      },
      "source": [
        "classifier = TextClassifier.load('sentiment-fast')\n",
        "\n",
        "#Loop over the first  10  reviews and for each one apply flair's Sentence method on the processed review text\n",
        "for i in range(10):\n",
        "  sen_list = Sentence(df[\"reviews_processed\"].iloc[i]) #use Sentence method  on each cell\n",
        "  classifier.predict(sen_list) #classifier.predict on the Sentence[cell]\n",
        "  print(df[\"reviews_processed\"].iloc[i]) #print the reviews\n",
        "  print(sen_list.labels) #print the lables\n",
        "\n",
        "#compute the sentiments of 100 and check time\n",
        "start1 = time.time() #compute the time\n",
        "for i in range(100):\n",
        "  sen_list1 = Sentence(df[\"reviews_processed\"].iloc[i])\n",
        "  classifier.predict(sen_list1)\n",
        "end1 = time.time()\n",
        "print(f\"The Runtime of compute the sentiments of 100 datapoints: {round((end1 - start1),3)}\")\n",
        "\n",
        "#compute the sentiments of 1000 and check time\n",
        "start2 = time.time() #compute the time\n",
        "for i in range(1000):\n",
        "  sen_list2 = Sentence(df[\"reviews_processed\"].iloc[i])\n",
        "  classifier.predict(sen_list2)\n",
        "end2 = time.time()\n",
        "print(f\"The Runtime of compute the sentiments of 1000 datapoints: {round((end2 - start2),3)}\")\n",
        "\n",
        "#compute the sentiments of 10000 and check time\n",
        "start3 = time.time() #compute the time\n",
        "for i in range(10000):\n",
        "  sen_list3 = (Sentence(df[\"reviews_processed\"].iloc[i]))\n",
        "  classifier.predict(sen_list3)\n",
        "end3 = time.time()\n",
        "print(f\"The Runtime of compute the sentiments of 10000 datapoints: {round((end3 - start3),3)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keep buying madden every year hoping get back football year version little better last year saying game look great thing wrong animation way player always tripping br br gameplay still slowed bloated control used take two button giant pita get done opponent snap ball play clock run br br turbo button back player movement still slow awkward liked last year version guessing like chance play anything training online game crossing finger hoping rest br br one thing recommend buy madden bundle game come download hate trading gamestop\n",
            "[NEGATIVE (0.9999)]\n",
            "awesome\n",
            "[POSITIVE (0.9971)]\n",
            "prepping end world one thing installed pc hail great yuri\n",
            "[POSITIVE (0.8517)]\n",
            "perfect\n",
            "[POSITIVE (0.9941)]\n",
            "awesome\n",
            "[POSITIVE (0.9971)]\n",
            "awesome\n",
            "[POSITIVE (0.9971)]\n",
            "like new skill like herbalism camping fun also like new build mode item\n",
            "[POSITIVE (0.8617)]\n",
            "super\n",
            "[POSITIVE (0.9509)]\n",
            "excellent fast secure\n",
            "[POSITIVE (0.9975)]\n",
            "ok\n",
            "[POSITIVE (0.564)]\n",
            "The Runtime of compute the sentiments of 100 datapoints: 0.248\n",
            "The Runtime of compute the sentiments of 1000 datapoints: 2.524\n",
            "The Runtime of compute the sentiments of 10000 datapoints: 26.442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhOeeGJVz2LX"
      },
      "source": [
        "I first looped through the first 10 reviews in the column I created in the previous section and in each cell I ran the Sentence function and then the classifier.predict. The classifier.predict function tries to understand whether the reviews are positive or negative in nature. I printed the ten reviews and their labels. It can be seen that for each review there are two parameters: positive / negative and score.\n",
        "Then I made three loops when each ran on a different range of numbers. For each loop I use the sentence function and the prediction function. In addition I measured the run time of each loop. As we can see the time rises as the range is bigger.\n",
        "\n",
        "**Do the generated sentiments represent the text?**\n",
        "\n",
        "It can be seen that there are positive and negative reactions and that the classifier manages very well to classify the reactions to positive and negative in a high rating. That is, It can be concluded that generated sentiments represent the text very well.\n",
        "\n",
        "**Extrapolate and estimate how long would it take to compute the sentiments over all data points in your category**\n",
        "\n",
        "The runtime seems to jump in multiples of 10 (+-), so for data like ours (a little less then 100,000 lines ) the estimataion will be that the runtime will be around 300-400.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tugmwslS8nW"
      },
      "source": [
        "**2.(c) [6 pt]** To speed up the sentiment retrieval, we would like to implement a `mini-batch` approach: \n",
        "We first create a list of sentences `Sentence(text)``s for all input texts, \n",
        "and then go over them in groups of size `mini_batch_size`, and apply the `.predict` function to the entire  `mini-batch` instead of $1$ data-point at a time: \n",
        "\n",
        "1. Define a `batch` function that has an iterable and a `mini-batch` size `int` as inputs, and yields out the mini-batches of the iterable. \n",
        "\n",
        "2. Define a `get_sentiment` function that takes an `np.array` of text datapoints as input, and outputs a `np.array` of the label objects from the sentiments. Make sure you use the `mini_batch_size=128` and `verbose=True` parameters within the `.predict` method. Also, make sure you call the `.predict` method only once, on a list of `Sentence` objects. \n",
        "\n",
        "3. Run the above functions on all the processed text datapoints of `df` using a `mini_batch_size` of `128`, and a `batch size` of `10,000`. Print out the total time it takes and compare it to the predicted time from **2.(b)**.\n",
        "\n",
        "4. Add both the sentiments' scores  (`sent_score`) and the sentiments' values (`sent_value`) as new separate colomns (new features) in `df`. \n",
        "\n",
        "Execute a `df.head()` command to view the top values when done. \n",
        "\n",
        "**Note:** Running the functions on all data points may take a few minutes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_pL2AybrU12"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_f-X5r3ns3E"
      },
      "source": [
        "#According to the clarification given by the lecturer about this part there was no need to build the batch function.\n",
        "%%capture\n",
        "#Define a get_sentiment function that takes an np.array of text datapoints as input, and outputs a np.array of the label objects from the sentiments\n",
        "def get_sentiment(array):\n",
        "  sentence_list = [] #empty list\n",
        "  for i in range(len(array)): \n",
        "    sentence_list.append(Sentence(array.iloc[i])) #create Sentence and add it to the list \n",
        "  classifier.predict(sentence_list,mini_batch_size=128, verbose=True)  #predict all the  Sentence in the list together\n",
        "  return [sentence_list[i].labels for i in range(len(sentence_list))] #returnt the labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5l9Q11VwH1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "15b3cb4b-6067-4685-b243-b37afb28a97f"
      },
      "source": [
        "#3.Run the above functions on all the processed text datapoints of df using a mini_batch_size of 128, and a batch size of 10,000. \n",
        "#Print out the total time it takes and compare it to the predicted time from 2.(b).\n",
        "\n",
        "#use my function on all the processed text datapoints of df[reviews_processed]\n",
        "labs = get_sentiment(df[\"reviews_processed\"])\n",
        "\n",
        "#calculate the time of get_sentiment on 10000 rows\n",
        "start4 = time.time()\n",
        "get_sentiment(df[\"reviews_processed\"][:10000])\n",
        "end4 = time.time()\n",
        "print(f\"Runtime of compute the sentiments of 10000 datapoints by get_sentiment function: {round((end4 - start4),3)}\") #print the time\n",
        "\n",
        "#4.Add both the sentiments' scores (sent_score) and the sentiments' values (sent_value) as new separate colomns (new features) in df.\n",
        "#add two list ot values and scors from the lables pbjects\n",
        "scores =[]\n",
        "values =[]\n",
        "for i in range(len(df[\"reviews_processed\"])):\n",
        "  scores.append(round(labs[i][0].score,3))\n",
        "  values.append(labs[i][0].value)\n",
        "\n",
        "#add the new columns to the data\n",
        "df[\"sent_score\"] = scores\n",
        "df[\"sent_value\"] = values\n",
        "\n",
        "#Execute a df.head() command to view the top values when done.\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing on batch 1133: 100%|██████████| 1133/1133 [03:01<00:00,  6.25it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:07<00:00, 11.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime of compute the sentiments of 10000 datapoints by get_sentiment function: 20.799\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>reviews_processed</th>\n",
              "      <th>sent_score</th>\n",
              "      <th>sent_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>21269168</td>\n",
              "      <td>RSH1OZ87OYK92</td>\n",
              "      <td>B013PURRZW</td>\n",
              "      <td>603406193</td>\n",
              "      <td>Madden NFL 16 - Xbox One Digital Code</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>A slight improvement from last year.</td>\n",
              "      <td>I keep buying madden every year hoping they ge...</td>\n",
              "      <td>2015-08-3</td>\n",
              "      <td>keep buying madden every year hoping get back ...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>133437</td>\n",
              "      <td>R1WFOQ3N9BO65I</td>\n",
              "      <td>B00F4CEHNK</td>\n",
              "      <td>341969535</td>\n",
              "      <td>Xbox Live Gift Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome</td>\n",
              "      <td>2015-08-3</td>\n",
              "      <td>awesome</td>\n",
              "      <td>0.997</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>45765011</td>\n",
              "      <td>R3YOOS71KM5M9</td>\n",
              "      <td>B00DNHLFQA</td>\n",
              "      <td>951665344</td>\n",
              "      <td>Command &amp; Conquer The Ultimate Collection [Ins...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Hail to the great Yuri!</td>\n",
              "      <td>If you are prepping for the end of the world t...</td>\n",
              "      <td>2015-08-3</td>\n",
              "      <td>prepping end world one thing installed pc hail...</td>\n",
              "      <td>0.852</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>113118</td>\n",
              "      <td>R3R14UATT3OUFU</td>\n",
              "      <td>B004RMK5QG</td>\n",
              "      <td>395682204</td>\n",
              "      <td>Playstation Plus Subscription</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Perfect</td>\n",
              "      <td>2015-08-3</td>\n",
              "      <td>perfect</td>\n",
              "      <td>0.994</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>US</td>\n",
              "      <td>22151364</td>\n",
              "      <td>RV2W9SGDNQA2C</td>\n",
              "      <td>B00G9BNLQE</td>\n",
              "      <td>640460561</td>\n",
              "      <td>Saints Row IV - Enter The Dominatrix [Online G...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>2015-08-3</td>\n",
              "      <td>awesome</td>\n",
              "      <td>0.997</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  marketplace customer_id  ... sent_score sent_value\n",
              "1          US    21269168  ...      1.000   NEGATIVE\n",
              "2          US      133437  ...      0.997   POSITIVE\n",
              "3          US    45765011  ...      0.852   POSITIVE\n",
              "4          US      113118  ...      0.994   POSITIVE\n",
              "5          US    22151364  ...      0.997   POSITIVE\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWYV_fVIz9xw"
      },
      "source": [
        "I built a function: get_sentiment - The function creates an empty list and then runs in a loop on the length of the array it was given. For each member in the array it runs the Sentence function and then adds it to the empty list. After this run classifier.predict on the list of sentences we received by 128 mini_batch. The function returns the labels of each sentence from the list of sentences it has created.\n",
        "\n",
        "Next I created two lists. One that goes through the entire reviews_processed column and activates the Sentence function for each cell. The second only goes over the first 10000 rows in the same column and does the same thing.\n",
        "I ran the get_sentiment function I built on the list of 10000 \"sentences\" and checked how long it takes to run. As we see in this way the run is much faster than in the previous section.\n",
        "\n",
        "Then I extracted the values ​​and score of the first list I made (the one that contains \"sentences\" of the whole reviews_processed column). I added two new columns to the data: scores and values.\n",
        "\n",
        "**compare it to the predicted time from 2.(b).**\n",
        "\n",
        "As we can see the predicted time is faster then the predicted time from 2.(b) \n",
        "\n",
        "(According to the clarification given by the lecturer in this part I did not build the batch function but I built it and used it in part 4.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-M-kX2Alj51"
      },
      "source": [
        "**2.(d) [8 pt] Setting binary variables:** \n",
        "\n",
        "Write a function that modifies a `pandas` data-frame as follows:\n",
        "\n",
        "*   To simplify the target variable and get a binary classification problem, map star ratings of `1,2` to `0`, and `4,5` to `1` (corresponding to `negative` and `positive` sentiments respectively). Filter neutral star ratings of `3`.\n",
        "\n",
        "In addition:\n",
        "\n",
        "*   Make sure the types of the data is compatible with modeling\n",
        "*   Set binary variables values to zero/one where applicable\n",
        "*   Get rid of `np.nan, np.inf, -np.inf`\n",
        "\n",
        "Run the function on the data-frame `df` and then run `df.head()` to view the top values when done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPQf05iY3si_"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7zAW0Phjix3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "14874837-b30a-46c7-c135-f4b101c704f8"
      },
      "source": [
        "#creat a modifing function\n",
        "def modifies_func(data):\n",
        "#map star ratings of 1,2 to 0, and 4,5 to 1\n",
        "  data[\"binstar\"] = data[\"star_rating\"] #create new column\n",
        "  for i in range(len(data[\"star_rating\"])): \n",
        "    if data[\"star_rating\"].iloc[i] == \"1\":  #according the conditions\n",
        "      data[\"binstar\"].iloc[i] = 0\n",
        "    if data[\"star_rating\"].iloc[i] == \"2\":\n",
        "      data[\"binstar\"].iloc[i] = 0\n",
        "    if data[\"star_rating\"].iloc[i] == \"4\" :\n",
        "      data[\"binstar\"].iloc[i] = 1\n",
        "    if data[\"star_rating\"].iloc[i] == \"5\":\n",
        "      data[\"binstar\"].iloc[i] = 1\n",
        "  \n",
        "  #Filter neutral star ratings of 3.\n",
        "  data = data[data[\"binstar\"] != \"3\"]\n",
        "\n",
        "  #change the value according POSITIVE\\NEGATIVE\n",
        "  for i in range(len(data[\"sent_value\"])): \n",
        "    if data[\"sent_value\"].iloc[i] == \"POSITIVE\":\n",
        "      data[\"sent_value\"].iloc[i] = 1\n",
        "    if data[\"sent_value\"].iloc[i] == \"NEGATIVE\":\n",
        "      data[\"sent_value\"].iloc[i] = 0\n",
        "  \n",
        "  #Set binary variables values to zero/one where applicable \n",
        "  data[\"star_rating\"] = data[\"star_rating\"].astype(float)\n",
        "  data[\"sent_score\"] = data[\"sent_score\"].astype(float)\n",
        "  data[\"total_votes\"] = data[\"total_votes\"].astype(int)\n",
        "  data[\"helpful_votes\"] = data[\"helpful_votes\"].astype(float)\n",
        "  data[\"product_parent\"] = data[\"product_parent\"].astype(float)\n",
        "  data[\"customer_id\"] = data[\"customer_id\"].astype(float)\n",
        "  \n",
        "#Get rid of np.nan, np.inf, -np.inf\n",
        "  data.replace('', np.nan, inplace=True)\n",
        "  data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "  data.dropna(inplace=True)\n",
        "\n",
        "  return data\n",
        "#Run the function on the data-frame df  \n",
        "df = modifies_func(df)\n",
        "#df.head() to view the top values\n",
        "df.head()\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>reviews_processed</th>\n",
              "      <th>sent_score</th>\n",
              "      <th>sent_value</th>\n",
              "      <th>binstar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>21269168.0</td>\n",
              "      <td>RSH1OZ87OYK92</td>\n",
              "      <td>B013PURRZW</td>\n",
              "      <td>603406193.0</td>\n",
              "      <td>Madden NFL 16 - Xbox One Digital Code</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>A slight improvement from last year.</td>\n",
              "      <td>I keep buying madden every year hoping they ge...</td>\n",
              "      <td>2015-08-3</td>\n",
              "      <td>keep buying madden every year hoping get back ...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>133437.0</td>\n",
              "      <td>R1WFOQ3N9BO65I</td>\n",
              "      <td>B00F4CEHNK</td>\n",
              "      <td>341969535.0</td>\n",
              "      <td>Xbox Live Gift Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome</td>\n",
              "      <td>2015-08-3</td>\n",
              "      <td>awesome</td>\n",
              "      <td>0.997</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>45765011.0</td>\n",
              "      <td>R3YOOS71KM5M9</td>\n",
              "      <td>B00DNHLFQA</td>\n",
              "      <td>951665344.0</td>\n",
              "      <td>Command &amp; Conquer The Ultimate Collection [Ins...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Hail to the great Yuri!</td>\n",
              "      <td>If you are prepping for the end of the world t...</td>\n",
              "      <td>2015-08-3</td>\n",
              "      <td>prepping end world one thing installed pc hail...</td>\n",
              "      <td>0.852</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>113118.0</td>\n",
              "      <td>R3R14UATT3OUFU</td>\n",
              "      <td>B004RMK5QG</td>\n",
              "      <td>395682204.0</td>\n",
              "      <td>Playstation Plus Subscription</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Perfect</td>\n",
              "      <td>2015-08-3</td>\n",
              "      <td>perfect</td>\n",
              "      <td>0.994</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>US</td>\n",
              "      <td>22151364.0</td>\n",
              "      <td>RV2W9SGDNQA2C</td>\n",
              "      <td>B00G9BNLQE</td>\n",
              "      <td>640460561.0</td>\n",
              "      <td>Saints Row IV - Enter The Dominatrix [Online G...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>2015-08-3</td>\n",
              "      <td>awesome</td>\n",
              "      <td>0.997</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  marketplace  customer_id       review_id  ... sent_score  sent_value binstar\n",
              "1          US   21269168.0   RSH1OZ87OYK92  ...      1.000           0       0\n",
              "2          US     133437.0  R1WFOQ3N9BO65I  ...      0.997           1       1\n",
              "3          US   45765011.0   R3YOOS71KM5M9  ...      0.852           1       1\n",
              "4          US     113118.0  R3R14UATT3OUFU  ...      0.994           1       1\n",
              "5          US   22151364.0   RV2W9SGDNQA2C  ...      0.997           1       1\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U98qX6Va0aAG"
      },
      "source": [
        "In this section I have built a function whose purpose is to arrange the data in a way that will fit for the following sections. The function prepares the data for us to run a classification model on it later.\n",
        "\n",
        "First I added a column called binstar (the target column) and convert it to binari. It has values ​​0,1,3. 0 if the star_rating column has a score of 1 or 2 and 1 if it has a score of 4 or 5. I filtered the data from binstr = 3 so the data contain only 0 or 1 value. Then I turned the variable \"values\" to 1 if positive and to 0 if negative, removed missing or (+-)infinite values and changed all the columns that have numeric values ​​to float or int objects. Finally I Run the function on the data-frame df and show the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgurFap3fwv2"
      },
      "source": [
        "**2.(e) [1 pt]** In addition to the `flair` sentiment features we would like to add also a `TfidfVectorizer` feature. \n",
        "\n",
        "Run the code cell below to create a numpy array named `final_df` that will be used for modeling in **Part 3**. Add a line printing the shape (number of samples and features) of the resulting array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1iV4L247A3h"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u26cREvfx78H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "babfcdee-8910-49c2-8ac4-9eed14183788"
      },
      "source": [
        "# Add the features of the dataframe that you want to transform and/or combine\n",
        "mapper = DataFrameMapper([\n",
        "     ('reviews_processed', TfidfVectorizer(max_features=100)),\n",
        "     ('helpful_votes', None),\n",
        "     ('total_votes', None),\n",
        "     ('sent_score', None),\n",
        "     ('sent_value', None)\n",
        " ], df_out=False)\n",
        "\n",
        "\"\"\"\n",
        "Use the fit_transform method to transform the old dataframe into a new one\n",
        "that can be fed to the machine learning algorithm.\n",
        "\"\"\"\n",
        "mapper_fit = mapper.fit(df)\n",
        "final_df = mapper.transform(df) # a numpy array \n",
        "\n",
        "#print the shape (number of samples and features) of the resulting array.\n",
        "fin_df_shape = final_df.shape\n",
        "print(\"DF Shape ={}\\nData points = {}\\nFeatures = {}\".format(fin_df_shape, fin_df_shape[0], fin_df_shape[1])) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DF Shape =(133389, 104)\n",
            "Data points = 133389\n",
            "Features = 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MY03KFrW3i3"
      },
      "source": [
        "### **Part 3: Fitting a classification model to a large dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc_D7bB8vTi_"
      },
      "source": [
        "Our goal is to predict the binarized star rating (`binstar`) variable using the other features for each review.   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cLgIus0hpDN"
      },
      "source": [
        "**3.(a) [6 pt]** Create a `x_train,x_test,y_train,y_test` random split of the `final_df` and the target `binstar`, with the test set containing $20\\%$ of the data and the training set containing $80\\%$ of the data. \n",
        "\n",
        "In addition, normalize/standardize the data as you wish. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob7eRKo3Sisd"
      },
      "source": [
        "#set the results\n",
        "random.seed(100)\n",
        "\n",
        "#create a x_train,x_test,y_train,y_test random split of the final_df and the target binstar using train_test_split from sklearn packege\n",
        "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(final_df) , df[\"binstar\"], test_size = 0.20)\n",
        "\n",
        "#I kept a copy of data train, data test and the target variable without normalization because I will need you after this in question 4.\n",
        "X_train_not_norm, X_test_not_norm,  = X_train, X_test\n",
        "y_train_not_norm, y_test_not_norm = y_train, y_test\n",
        "\n",
        "#normalize the data by Normalizer from sklearn\n",
        "X_test = Normalizer().fit_transform(X_test) \n",
        "X_train = Normalizer().fit_transform(X_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTIoW_nl0jmO"
      },
      "source": [
        "In this section we were asked to fit a classification model to a large data field when our variable variable is binstar. To do this we first apply our data to the train and test for the explanatory variables (X) and for the objective variable (Y). I performed this operation on me by the built-in train_test_split function of the sklearn package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_fjhfeui1Sn"
      },
      "source": [
        "**3.(b) [5 pt]** Fit a logistic regression model to the training set. \n",
        "You may use the `sklearn` package. Print the train and test model accuracy\n",
        "<!-- *   Report the precision, recall, and f1-score and explain each metric. -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9o9eRxa_4tj"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTKJwTYYDnx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f971b02c-c162-4249-b07e-c58ae86e1961"
      },
      "source": [
        "#Fit a logistic regression model to the training set\n",
        "reg_train = LogisticRegression().fit(X_train, y_train)\n",
        "accuracy_train = reg_train.score(X_train, y_train)\n",
        "accuracy_test = reg_train.score(X_test, y_test)\n",
        "\n",
        "#Print the train  model accuracy\n",
        "print(\"Logistic Regression model - train accuracy:\", round(accuracy_train,3))\n",
        "\n",
        "#Print the test  model accuracy  \n",
        "print(\"Logistic Regression model - test accuracy:\", round(accuracy_test,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression model - train accuracy: 0.883\n",
            "Logistic Regression model - test accuracy: 0.882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u94l9jN90neV"
      },
      "source": [
        "Now, I applied a logistic regression model (by a built-in function, LogisticRegression from a sklearn package) once to the Tain data and once to the test data. After this I ran the score function to calculate the accuracy index of each of the regressions. It can be seen that the accuracy is very high both in regression on the train data and also in regression on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7U-BnmJkMx-"
      },
      "source": [
        "**3.(c) [6 pt]** For different lengths of $n = 10 \\times 2^k$, for $k=0,1,..,14$ extract only the first $n$ values in the train set (i.e. first rows of `x_train` and first values of `y_train`) and use them to fit the logistic regression model. (If $n$ is larger than the total number of rows, set $n$ to the actua number).\n",
        "\n",
        "Plot the training error (for each $k$ on the appropriate train set) and test error (on the entire test set) vs. the sample size $n$ shown on a log-scale. Do we see an improvement when increasing $n$? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoO-mmLE_03I"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ukLzEfxeol2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "d7982cc5-5dd9-42e4-e669-72e85e9c98a1"
      },
      "source": [
        "#For different n=10×2k , for  k=0,1,..,14  extract only the first  n  values in the train set \n",
        "n = []\n",
        "for k in range(15):\n",
        "  if 10*(2**k) < len(X_train):\n",
        "    n.append(10*(2**k))\n",
        "  if 10*(2**k) > len(X_train): #If the number is greater than the length of the data then we will add the length of the data to the list.\n",
        "    n.append(len(X_train))\n",
        "\n",
        "#use the numers to take parts of the data and fit the logistic regression model \n",
        "train_error = []\n",
        "test_error = []\n",
        "for i in range(len(n)):\n",
        "  regg_train = LogisticRegression().fit(X_train[:n[i]], y_train[:n[i]])\n",
        "  train_error.append(1-regg_train.score(X_train[:n[i]], y_train[:n[i]])) #comput error for test\n",
        "  test_error.append(1-regg_train.score(X_test, y_test)) #comput error for test\n",
        "\n",
        "#create the data frame for the plot\n",
        "data_plot = pd.DataFrame(train_error,columns = [\"train_error\"])\n",
        "data_plot[\"test_error\"] = test_error\n",
        "data_plot[\"log(n)\"] = np.log10(n)\n",
        "\n",
        "#plot\n",
        "fig,ax = plt.subplots()\n",
        "ax.plot(data_plot[\"log(n)\"],data_plot[\"train_error\"], color=\"pink\", marker=\"o\")\n",
        "ax.plot(data_plot[\"log(n)\"], data_plot[\"test_error\"],color=\"red\",alpha = 0.4,marker=\"o\")\n",
        "\n",
        "# set labels\n",
        "ax.set_xlabel(\"Log(n)\",fontsize=14)\n",
        "ax.set_ylabel(\"Test Error & Train Error\",fontsize=14)\n",
        "ax.set_title('Test Error & Train Error for each K VS. Log(n)',fontsize=18)\n",
        "plt.legend([\"Train Error\",'Test Error'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWSF1RFk0rbU"
      },
      "source": [
        "In this section I examined how the accuracy changes for different data sizes (or the opposite way: how the error decreases as the data size increases). For this purpose I built a \"n\" list containing 15 values ​​equal to 10*2^k when K runs up to 14 (including 0). (If the 10*2^k > data length I add the len(data) into n[i] ). Next I performed a logistic regression, each time for a larger portion of the data (according to the n size) and calculated the test and train error for each such regression.\n",
        "I created a new data and presented  in a plot the errors of the train and the test for each size of the data (according to n) when the axis is X is a log (n).\n",
        "\n",
        "**Do we see an improvement when increasing n ?**\n",
        "\n",
        "It can be clearly seen that the error decreases as the n is greater i.e. the larger the data. We can see it for the both test for the train. \n",
        "In addition it can be seen that for small part of the data there are little jumps but in almost all the values the test error is larger than the train error (as expected) and the more data is used the error decreases and at the end when reaching all the data the distance between the errors becomes minimal. That is, as there are more observations the accuracy increases and the error decreases and the distance between the accuracy (or the error) between the test and the train decreases, as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e78AxxLkbri"
      },
      "source": [
        "**3.(d) [9 pt] Combining models from similar data:** \n",
        "\n",
        "* Find the maximal power $k$ such that the test error for $n = 10 \\times 2^k$ is at least $0.02$ lower than the test error for the  maximal $n$ (denoted $n_{max}$ you have used in **3.(c)**.\n",
        "\n",
        "* Split the maximal training set you have used into $n_{max} / n$ random blocks of equal size. \n",
        "\n",
        "* Run a logistic regression model on each block separately\n",
        "\n",
        "* Finally, average the fitted models coefficients to get a combined model. \n",
        "\n",
        "* Report the train and test accuracy for the combined model on the entire (unified) training and test set.  \n",
        "\n",
        "* How does it compare to the results from the **3.(c)** where fitting the model using the entire dataset? is the accuracy diminished/comparable/improved?\n",
        "\n",
        "* At what circumstances would you recommend this approach of splitting the data to blocks and combining the models?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLwy1JITJgLR"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV2OLvlKJsWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dadd060a-6509-4168-8eef-961cfdca1e7a"
      },
      "source": [
        "#set the results\n",
        "random.seed(100)\n",
        "\n",
        "#comput the max k\n",
        "max_k_test = np.round(test_error - test_error[-1],3)\n",
        "inx = 0\n",
        "for i in range(len(max_k_test)):\n",
        "  if max_k_test[i]> 0.02:\n",
        "    inx = i\n",
        "  \n",
        "#Split the maximal training set you have used into  nmax/n  random blocks of equal size.\n",
        "\n",
        "#compute the the blocks\n",
        "maxn = n[-1] \n",
        "n_mechane = 10*2**inx \n",
        "blocks = int(round(maxn/n_mechane,0))\n",
        "lines = list(range(0,len(X_train)))\n",
        "coeff = [] #list for the coeff\n",
        "\n",
        "#run over the block and preforme LogisticRegression\n",
        "for i in range(blocks):  \n",
        "  subset = list(random.sample(lines,round(len(X_train)/blocks-1))) #randomize the train\n",
        "  lines = [i for i in lines if i not in subset]\n",
        "  y_sub = np.array(y_train)[subset] #create the y (for this block)\n",
        "  X_sub = X_train[subset,:] #remove the y from the data\n",
        "  log_reg = LogisticRegression().fit(X_sub,y_sub) #fit LogisticRegression\n",
        "  coeff.append(log_reg.coef_) #take coef\n",
        "\n",
        "#average the fitted models coefficients to get a combined model.\n",
        "#calculate the mean of each list of coeff in the big doeff list\n",
        "coeff_sum = coeff[0]\n",
        "for i in range(1,len(coeff)):\n",
        "  coeff_sum += coeff[i]\n",
        "coeff_mean = coeff_sum/len(coeff)\n",
        "\n",
        "#build the model\n",
        "logit_model_train = e**(X_train@coeff_mean[0])/ (1+e**(X_train@coeff_mean[0]))\n",
        "log_model_test = e**(X_test@coeff_mean[0])/(1+e**(X_test@coeff_mean[0]))\n",
        "\n",
        "#the y should be binary (Logistic Regression) so i built trashhold = 0.5, if logit_model >=  0.5 so 1 and  if logit_model >=  0.5 so 0\n",
        "for i in range(len(logit_model_train)):\n",
        "  if logit_model_train[i] == 0.5:\n",
        "    logit_model_train[i] = 1\n",
        "  if logit_model_train[i] > 0.5:\n",
        "    logit_model_train[i] = 1\n",
        "  if logit_model_train[i] < 0.5:\n",
        "    logit_model_train[i] = 0\n",
        "\n",
        "for i in range(len(log_model_test)):\n",
        "  if log_model_test[i] == 0.5:\n",
        "    log_model_test[i] = 1\n",
        "  if log_model_test[i] > 0.5:\n",
        "    log_model_test[i] = 1\n",
        "  if log_model_test[i] < 0.5:\n",
        "    log_model_test[i] = 0\n",
        "\n",
        "#Report the train and test accuracy for the combined model on the entire (unified) training and test set.\n",
        "mse_logit_model_train = ((y_train-logit_model_train)**2).sum() /len(logit_model_train) #the formula of mse\n",
        "mse_log_model_test = ((y_test-log_model_test)**2).sum() /len(log_model_test) #the formula of mse\n",
        "acuur_logit_train = round(1-mse_logit_model_train,3)\n",
        "acuur_logit_test = round(1-mse_log_model_test,3)\n",
        "\n",
        "print(\"The train accuracy for the combined model on the entire data: \", acuur_logit_train)\n",
        "print(\"The test accuracy for the combined model on the entire data: \", acuur_logit_test)\n",
        "\n",
        "#compare to the accuracy of  3.c (print the accuracy estimates to make the comparison easier)\n",
        "print(\"The train accuracy for the model on the entire data from Q 3.c: \", round(1-data_plot[\"train_error\"][14],3))\n",
        "print(\"The test accuracy for the model on the entire data from Q 3.c: \", round(1-data_plot[\"test_error\"][14],3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The train accuracy for the combined model on the entire data:  0.791\n",
            "The test accuracy for the combined model on the entire data:  0.788\n",
            "The train accuracy for the model on the entire data from Q 3.c:  0.883\n",
            "The test accuracy for the model on the entire data from Q 3.c:  0.882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVB0olYY0xk5"
      },
      "source": [
        "The purpose of this section was to run a logistic regression in parts and use the coefficient's averages to manually construct a logistic regression model and then check how the accuracy index changes in this case to compare the accuracy index of the model in the previous section.\n",
        "\n",
        "In this section I randomly divided the data into blocks of the same size (n_max/n). next I ran on each data block logistic regression and saved its coefficients. After I got a list of coefficient lists, I did an average for each sub-list so in the end I got a list of coefficient averages.\n",
        "Following this I manually built a logistic regression model with the train data and the list of the coefficient averages by the familiar formula of logistic regression. I also added a condition that wiii assures that the Y obtained from the model will be binary (Properly in logistical regression) Finally I calculated the MSE of the model (accuracy) and the error (1-MSE) and presented the results.\n",
        "\n",
        "**How does it compare to the results from the 3.(c) where fitting the model using the entire dataset? is the accuracy diminished/comparable/improved?**\n",
        "\n",
        "It can be seen that there is differences in the accuracy index compared to the previous part. The combine model i built here has lower accuuracy then the model on the entire data on 3.c. This may be due to the fact that regression on the blocks retains features that do not represent all the data, so the accuracy index decreases when we compute it on all the data together.\n",
        "\n",
        "**At what circumstances would you recommend this approach of splitting the data to blocks and combining the models?**\n",
        "\n",
        "In this method we actually divide the data into blocks when for each block logistic regression is run. One of the advantages of the method is the ability to preserve interesting or unexpected results in each block specifically that we cannot see when we do logistic regression on all the data together. Therefore, perhaps use this method in a situation where the data is arranged in a certain way i.e. the data is composed of parts and each part has similar properties. So in this case if we apply logistic regression on each part we may get better accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ydldpyMCdXZ"
      },
      "source": [
        "**3.(e) [10 pt] Combining models from different datasets:** \n",
        "\n",
        "* Pick $10$ different categories from the Amazon reviews dataset.  \n",
        "\n",
        "* For each dataset, read a batch of $100,000$ examples and split to train/test randoly with an `80%|20%` ratio as before. \n",
        "*  **Note:** You may pick large categories. **Do not** download the whole file as in  **1.(d)**. Instead, use `readlines` to download only the first $100,000$.\n",
        "\n",
        "* Run a logistic regression model on each category separately and report the train/test accuracies in a table. \n",
        "\n",
        "* Finally, average the fitted models coefficients from all categories to get a `combined model`. \n",
        "\n",
        "* Report the train and test accuracy for the `combined model` on the training and test set of each category separately.  \n",
        "\n",
        "* Did adding $\\times10$ more examples help in improving the accuracy compared to fitting each category separately? why do you think this happened?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT7m3aNomyrp"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wokdNMhrm0tH"
      },
      "source": [
        "%%capture\n",
        "#1.take 10 categoris \n",
        "ten_cat = filter_keys[9:19] \n",
        "\n",
        "#Pick  10  different categories from the Amazon reviews dataset.\n",
        "big_list = []\n",
        "for i in range(len(ten_cat)):\n",
        "  fileToStream2 = ten_cat[i][0]\n",
        "# Reading the file (may take time?)\n",
        "  s3conn.Bucket('amazon-reviews-pds').download_file(fileToStream2, 'tmp.gz')\n",
        "  % ls /content/ -lah\n",
        "  with gzip.open('/content/tmp.gz', 'rb') as f_in:\n",
        "      big_list.append(f_in.readlines(10000000)) #Because each category has a number of different bits I chose to read 10000000 and then cut the data to 10000 lines as required.\n",
        "\n",
        "#2.For each dataset, read a batch of  10000  examples and  process them by the functions constructed in Part 2.\n",
        "lists= []\n",
        "for j in range(len(big_list)):\n",
        "  lists.append([i.decode('utf-8') for i in big_list[j]]) #use decode to remove part of a string\n",
        "\n",
        "#create the 10 datas\n",
        "dfs = [\"df0\",\"df1\",\"df2\",\"df3\",\"df4\",\"df5\",\"df6\",\"df7\",\"df8\",\"df9\"] #list of the datas names\n",
        "d = {} #dict that will contain all 10 datas\n",
        "for name,l in zip(dfs,lists):\n",
        "    d[name] = pd.DataFrame([i.split('\\t') for i in l],columns= l[0].split('\\t')) #seperate lines\n",
        "    d[name] = d[name][:10000] #take only the 10000 first rows\n",
        "    d[name] = d[name].drop(labels=[0], axis=0) #remove first row (the col names)\n",
        "    d[name] = df_function(d[name],\"reviews_processed\") #use the df_function \n",
        "    lab = get_sentiment(d[name][\"reviews_processed\"]) #use the get_sentiment \n",
        "    \n",
        "    scores2 =[]\n",
        "    values2 =[]\n",
        "    for i in range(len(d[name][\"reviews_processed\"])): #add the two columns score and values\n",
        "      scores2.append(round(lab[i][0].score,3))\n",
        "      values2.append(lab[i][0].value)\n",
        "    \n",
        "    #add the to the data\n",
        "    d[name][\"sent_score\"] = scores2\n",
        "    d[name][\"sent_value\"] = values2\n",
        "    \n",
        "    #use the modifies_func\n",
        "    d[name] = modifies_func(d[name]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HCqM7zcc6ui",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "3930ddcd-b15d-412b-dbef-819ea4e78e64"
      },
      "source": [
        "#split to train/test randoly with an 80%|20% ratio as before.\n",
        "\n",
        "#set the results\n",
        "random.seed(100)\n",
        "\n",
        "#create lists to contain the acuuracy and coef\n",
        "accur_list_tra = []\n",
        "accur_list_tes = []\n",
        "coefficients_lists = []\n",
        "\n",
        "#create dicts to contain all the train and test datas\n",
        "trainin_dict_y = {}\n",
        "trainin_dict_x = {}\n",
        "testin_dict_y = {}\n",
        "testin_dict_x = {}\n",
        "\n",
        "#use the provided mapper function on the datas\n",
        "for name in dfs:\n",
        "  y = d[name][\"binstar\"] \n",
        "  mapper_fit = mapper.fit(d[name])\n",
        "  x = pd.DataFrame(mapper.transform(d[name]))# a numpy array \n",
        "  \n",
        "  #3.Run a logistic regression model on each category separately and report the train/test accuracies in a table.\n",
        "  \n",
        "  #create a x_train,x_test,y_train,y_test random split of the final_df and the target binstar\n",
        "  X_tra, X_tes, y_tra, y_tes = train_test_split(x , y, test_size = 0.20)\n",
        "  \n",
        "  #normalize the datas\n",
        "  X_tes = Normalizer().fit_transform(X_tes) \n",
        "  X_tra = Normalizer().fit_transform(X_tra) \n",
        "  trainin_dict_x[name] = X_tra \n",
        "  trainin_dict_y[name] = y_tra\n",
        "  testin_dict_x[name] = X_tes\n",
        "  testin_dict_y[name] = y_tes\n",
        "  \n",
        "  #Run a logistic regression and compute accuracies and coefficients\n",
        "  reg_tra = LogisticRegression().fit(X_tra, y_tra)\n",
        "  accur_list_tra.append(reg_tra.score(X_tra, y_tra))\n",
        "  coefficients_lists.append(reg_tra.coef_) \n",
        "  accur_list_tes.append(reg_tra.score(X_tes, y_tes))\n",
        "\n",
        "#4.create data frame of accuracies\n",
        "resi = pd.DataFrame(accur_list_tra, columns = [\"Accuracy train\"] )\n",
        "resi[\"Accuracy test\"] = accur_list_tes\n",
        "resi[\"Data\"] =[\"df_0\",\"df_1\",\"df_2\",\"df_3\",\"df_4\",\"df_5\",\"df_6\",\"df_7\",\"df_8\",\"df_9\"] \n",
        "display(resi)\n",
        "\n",
        "#5.average the fitted models coefficients from all categories to get a combined model.\n",
        "\n",
        "#calculate the mean of each list of coeff in the big coeff list\n",
        "coeff_sum2 = coefficients_lists[0]\n",
        "for i in range(1,len(coefficients_lists)):\n",
        "  coeff_sum2 += coefficients_lists[i]\n",
        "coeff_mean2 = coeff_sum2/len(coefficients_lists)\n",
        "\n",
        "#create accuracies lists for combine model\n",
        "combined_acuur_train = []\n",
        "combined_acuur_test = []\n",
        "\n",
        "#build the model\n",
        "for name in dfs:  \n",
        "  combined_model = e**(trainin_dict_x[name]@coeff_mean2[0])/ (1+e**(trainin_dict_x[name]@coeff_mean2[0]))\n",
        "  #the y should be binary (LogisticRegression) so i built trashhold = 0.5, if logit_model>=  0.5 so 1 and  if logit_model>=  0.5 so 0\n",
        "  for i in range(len(combined_model)):\n",
        "    if combined_model[i] == 0.5:\n",
        "      combined_model[i] = 1\n",
        "    if combined_model[i] > 0.5:\n",
        "      combined_model[i] = 1\n",
        "    if combined_model[i] < 0.5:\n",
        "      combined_model[i] = 0\n",
        "  mse_combine = ((trainin_dict_y[name]-combined_model)**2).sum() /len(trainin_dict_x[name]) #compute mse like the formola\n",
        "  combined_acuur_train.append(round(1-mse_combine,3)) #compute acurr\n",
        "\n",
        "  #same for test \n",
        "  combined_model_test = e**(testin_dict_x[name]@coeff_mean2[0])/ (1+e**(testin_dict_x[name]@coeff_mean2[0]))\n",
        "  #the y should be binary (LogisticRegression) so i built trashhold = 0.5, if logit_model>=  0.5 so 1 and  if logit_model>=  0.5 so 0\n",
        "  for i in range(len(combined_model_test)):\n",
        "    if combined_model_test[i] == 0.5:\n",
        "      combined_model_test[i] = 1\n",
        "    if combined_model_test[i] > 0.5:\n",
        "      combined_model_test[i] = 1\n",
        "    if combined_model_test[i] < 0.5:\n",
        "      combined_model_test[i] = 0\n",
        "  mse_combine_test = ((testin_dict_y[name]-combined_model_test)**2).sum() /len(testin_dict_x[name])\n",
        "  combined_acuur_test.append(round(1-mse_combine_test,3))\n",
        "\n",
        "#7.create data frame of the train and test accuracy for the combined model on the training and test set of each category separately.\n",
        "resi_combine = pd.DataFrame(combined_acuur_train, columns = [\"Accuracy combined train\"] )\n",
        "resi_combine[\"Accuracy combined test\"] = combined_acuur_test\n",
        "resi_combine[\"Data\"] =[\"df_0\",\"df_1\",\"df_2\",\"df_3\",\"df_4\",\"df_5\",\"df_6\",\"df_7\",\"df_8\",\"df_9\"] \n",
        "display(resi_combine) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy train</th>\n",
              "      <th>Accuracy test</th>\n",
              "      <th>Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.934795</td>\n",
              "      <td>0.921720</td>\n",
              "      <td>df_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.973990</td>\n",
              "      <td>0.968000</td>\n",
              "      <td>df_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.862329</td>\n",
              "      <td>0.861446</td>\n",
              "      <td>df_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.937569</td>\n",
              "      <td>0.933738</td>\n",
              "      <td>df_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.902727</td>\n",
              "      <td>0.901666</td>\n",
              "      <td>df_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.907556</td>\n",
              "      <td>0.894483</td>\n",
              "      <td>df_5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.907891</td>\n",
              "      <td>0.886201</td>\n",
              "      <td>df_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.961360</td>\n",
              "      <td>0.968573</td>\n",
              "      <td>df_7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.913072</td>\n",
              "      <td>0.920913</td>\n",
              "      <td>df_8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.887932</td>\n",
              "      <td>0.884346</td>\n",
              "      <td>df_9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy train  Accuracy test  Data\n",
              "0        0.934795       0.921720  df_0\n",
              "1        0.973990       0.968000  df_1\n",
              "2        0.862329       0.861446  df_2\n",
              "3        0.937569       0.933738  df_3\n",
              "4        0.902727       0.901666  df_4\n",
              "5        0.907556       0.894483  df_5\n",
              "6        0.907891       0.886201  df_6\n",
              "7        0.961360       0.968573  df_7\n",
              "8        0.913072       0.920913  df_8\n",
              "9        0.887932       0.884346  df_9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy combined train</th>\n",
              "      <th>Accuracy combined test</th>\n",
              "      <th>Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.863</td>\n",
              "      <td>0.851</td>\n",
              "      <td>df_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.934</td>\n",
              "      <td>0.942</td>\n",
              "      <td>df_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.831</td>\n",
              "      <td>0.840</td>\n",
              "      <td>df_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.910</td>\n",
              "      <td>0.916</td>\n",
              "      <td>df_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.869</td>\n",
              "      <td>0.869</td>\n",
              "      <td>df_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.878</td>\n",
              "      <td>0.867</td>\n",
              "      <td>df_5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.862</td>\n",
              "      <td>0.866</td>\n",
              "      <td>df_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.930</td>\n",
              "      <td>0.939</td>\n",
              "      <td>df_7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.882</td>\n",
              "      <td>0.900</td>\n",
              "      <td>df_8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.830</td>\n",
              "      <td>0.819</td>\n",
              "      <td>df_9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy combined train  Accuracy combined test  Data\n",
              "0                    0.863                   0.851  df_0\n",
              "1                    0.934                   0.942  df_1\n",
              "2                    0.831                   0.840  df_2\n",
              "3                    0.910                   0.916  df_3\n",
              "4                    0.869                   0.869  df_4\n",
              "5                    0.878                   0.867  df_5\n",
              "6                    0.862                   0.866  df_6\n",
              "7                    0.930                   0.939  df_7\n",
              "8                    0.882                   0.900  df_8\n",
              "9                    0.830                   0.819  df_9"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcvZ9snG9Vm_"
      },
      "source": [
        "In this question we ran a logistic regression model on 10 categories in the Amazon reviews dataset instead of just one category as in the previous sections. After reading the data I built a dictionary which contain all the datas. I activated all the functions I built in the second part on the 10 datas to adjust the data to run a logistic regression.\n",
        "\n",
        "After the early preparation I performed a logistical regression on each of the 10 datas and calculated the accuracy of the train and the test (shown below in the first table).\n",
        "\n",
        "Next I built a combined model of all 10 train datas. I did this by extracting the coefficients from all the regressions of all the data and built an overall model of all 10 data train by the familiar formula of a logistic regression. I calculated f(x) manually so I created a condition that would allow y to have values ​​of only 1 or 0. For the combined model I calculated the average MSE risk and accuracy. I did the same process for the 10 test datas. Then I calculated the accuracy of the combine train and combine test (shown below in the second table).\n",
        "\n",
        "**Did adding  ×10  more examples help in improving the accuracy compared to fitting each category separately? why do you think this happened?**\n",
        "\n",
        "It can be seen that in both tables the accuracy ranges between 0.8-0.9 for the train datas and for the test datas. Therefore I concluded that this method does not actually improve\\reduce the quality of the model. I think this is happening because it is possible that each category is different from the other in terms of its characterization and therefore it is more difficult to predict ten different categories in the same model instead of making a model for each category (Or if the accuracy does not decrease, at least it does not improve). When we average accuracy on all categories we actually lose important mains that are in each of the datas so the accuracy probably does not improve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-ELzeBtTg0e"
      },
      "source": [
        "### **Part 4: Fitting steaming data using Stochastic Gradient Descent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvUftvuakgFK"
      },
      "source": [
        "While we were able to create a predictive model, we used a small subset of the entire data. Using Colab's available resources, it is impossible to run the model on the entire data. To get around loading the entire data in memory at once, we can use `stochastic gradient descent` to train the model a `(mini) batch` at a time. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chw5jz8Gl5U6"
      },
      "source": [
        "**4.(a) [3 pt]** Create an `SGDClassifier` object with the logisitc regression loss. You may choose parameters for learning rate (the step-size at each iteration), penalties etc. <br> \n",
        "See [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier.partial_fit) for more details. If you don't understand a parameter, just keep the default value.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq9kXrAKA5nC"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfWmGEi_jfQq"
      },
      "source": [
        "GSDlogred = SGDClassifier(loss='log', random_state= 4000, shuffle=False) # add additional parameters to object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmSYX14B0-3I"
      },
      "source": [
        "After reading about the SGDClassifier algorithm I chose to add the  parameter shuffle and the parameter random_state= 4000 becuase  this parameter actually causes the algorithm to save its results in each run and therefor learn, deepen and improve its accuracy in each run.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr4TIPJzfAFK"
      },
      "source": [
        "**4.(b) [6 pt]**\n",
        "*  For the same `train_set` fitted in **3.(a), 3.(b)**, apply the SGD classifier for $50$ epochs (passes over the entire data) using the `partial_fit` method of the object `GSDlogred` you have created in **4.(a)**. <br>\n",
        "\n",
        "* Plot the loss of the classifier as a function of the number of epochs. Does it seem to converge? \n",
        "\n",
        "*  Compute the test error of the final output classifier. How does it compare to the error in **3.(b)** ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sodn8CDAnLun"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fbtgVwMYOqQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "76ed3594-ae54-4e2f-f20b-f6493afbdb5d"
      },
      "source": [
        "#same train and test as 3a\n",
        "x_train_GSD = X_train\n",
        "x_test_GSD = X_test\n",
        "y_train_GSD = y_train\n",
        "y_test_GSD = y_test\n",
        "\n",
        "#According to what I read in the SGDClassifier algorithm the target variable is 1 or -1 so I changed the 0 to -1.\n",
        "y_modi_GSD = y_train_GSD.replace(0,-1) #for y train\n",
        "y_test_GSD_modi = y_test_GSD.replace(0,-1) #for y test\n",
        "\n",
        "loss = []\n",
        "sgd_loss = [] #the mean loss list\n",
        "#apply the SGD classifier for  50  epochs  using the partial_fit method \n",
        "for n in range(50):\n",
        "  GSD_model = GSDlogred.partial_fit(x_train_GSD,y_train_GSD,classes=np.unique(y_train_GSD)) #apply the partial_fit\n",
        "  w = GSD_model.coef_ #compute the weight\n",
        "  f_x = np.dot(w,x_train_GSD.T) + GSD_model.intercept_[0] #compute the f(x) \n",
        "  vec = np.multiply(f_x[0],y_modi_GSD) #multiply the matrixs\n",
        "  loss = [] #cumpute the loss\n",
        "  for i in vec:\n",
        "    loss.append(math.log(1+math.exp(-i)))  #the loss according the formula\n",
        "  mean_loss = np.mean(loss) #mean on all the losses on one run \n",
        "  sgd_loss.append(mean_loss) #append to the average list of losses\n",
        "\n",
        "# plot loss of the classifier as a function of the number of epochs \n",
        "fig,ax = plt.subplots()\n",
        "#  a plot\n",
        "ax.plot(sgd_loss)\n",
        "# set labels\n",
        "ax.set_xlabel(\"Epochs\",fontsize=14)\n",
        "ax.set_ylabel(\"Loss of SGD Classifier\",fontsize=14)\n",
        "ax.set_title('The Loss of SGD Classifier as a function of the number of epochs',fontsize=18)\n",
        "plt.show()\n",
        "\n",
        "#Compute the test error of the final output classifier. \n",
        "error_GSD = (1-GSD_model.score(x_test_GSD,y_test_GSD))\n",
        "print(\"The test error for the  final output SGD Classifier: \", round(error_GSD,3))\n",
        "print(\"The accuracy for the  final output SGD Classifier: \", round(GSD_model.score(x_test_GSD,y_test_GSD),3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The test error for the  final output SGD Classifier:  0.122\n",
            "The accuracy for the  final output SGD Classifier:  0.878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YKIj3baBfUk"
      },
      "source": [
        "In this section I ran on the same train and test from 3a Q the SGD classifier for 50 epochs using the partial_fit method.\n",
        "In each run I calculated the weights by subtracting the coefficients from the model, the f(x) using the defined formula and the  y[i]f(x[i]). Next I calculated the loss of SGD classifier model using the defined formula.\n",
        "The purpose of this algorithm is to study and deepen the model so in each iteration it gets better and its loss is smaller. Indeed we can see in the graph that the loss is converging in each iteration.\n",
        "\n",
        "**Does it seem to converge?**\n",
        "\n",
        "It can be clearly seen that the loss is converging. This makes sense because the idea of ​​the model is that it learns with each re-run so after 50 iteration it is expected that the loss will be greatly reduced.\n",
        "\n",
        "**How the model accuracy compare to the error in 3.(b) ?**\n",
        "\n",
        "Compared to the accuracy index obtained in question 3B, it seems that there is a minimal difference in favor of the result of 3B when the accuracy index of the SGD classifier model is slightly lower.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJIQTXHKmSCm"
      },
      "source": [
        "**4.(c) [6 pt]** Pick one of the six *largest* categories in the AWS dataset. \n",
        "\n",
        "Modify and use the `obj` defined in the cell below, to `stream` (readlines) and loop through the gzip file of this category `100000` bytes at a time, with at least `100` batches (all done inside a `with` connection to the gzip file):  \n",
        "\n",
        "*   Make sure each `batch` is parsed appropriately (as have been done already)\n",
        "*   Create a `pandas` dataframe for each `batch` (within each loop) and print the number of rows (data points) in the `batch`\n",
        "*   Update the model parameters by executing the `GSDlogred.partial_fit` method on each processed batch (apply all the preprocessing steps we did in **Part 2** to get a processed numpy array, and the splitting to train and test sets before training the model as in **Part 3**). <br>\n",
        "For each batch report the test accuracy for this batch, and also the *average* test accuracy over all batches so far. Do you see an improvement as you use more and more batches?\n",
        "\n",
        "**Note:** Make sure that your fitting algorithm uses each data point in the batch only once, as is appropriate for the streaming model. \n",
        "Also make sure that when updating the parameters for each batch, the classifier is initialized with the parameters fitted already using previous batches. \n",
        "Modify the `GSDlogred` object if needed, before looping over batches, to accomodate these changes and other changes needed to deal with the data stream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46e3ZfUFA8KB"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hNPh2lySR--"
      },
      "source": [
        "%%capture\n",
        "maxCount = 100\n",
        "batch_size = 100000 #bytes \n",
        "\n",
        "#Modify the obj\n",
        "obj = s3conn.Object('amazon-reviews-pds', filter_keys[4][0]) \n",
        "d2= {} #dict for all the batch\n",
        "counter = 0 #create counter\n",
        "with gzip.GzipFile(fileobj=obj.get()[\"Body\"] ) as gzipfile:\n",
        "    while counter <= maxCount:\n",
        "        batch = [i.decode().replace('\"\"','\"').strip().split('\\t') for i in gzipfile.readlines(batch_size)]\n",
        "        \n",
        "        #define the name  and col names of each data batch\n",
        "        name = \"df\" + str(counter) \n",
        "        d2[name] = pd.DataFrame(batch,columns = ['marketplace', 'customer_id', 'review_id', 'product_id',\n",
        "       'product_parent', 'product_title', 'product_category', 'star_rating',\n",
        "       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
        "       'review_headline', 'review_body', 'review_date']) \n",
        "        d2[name] = d2[name].drop(labels=[0], axis=0)   \n",
        "        \n",
        "        #print the number of rows\n",
        "        print(d2[name].shape[0])\n",
        "        \n",
        "        #activate all the three function i created on section 2 for preprossecing \n",
        "        d2[name] = df_function(d2[name],\"reviews_processed\")\n",
        "        lab2 = get_sentiment(d2[name][\"reviews_processed\"])\n",
        "        scores3 =[]\n",
        "        values3 =[]\n",
        "        for i in range(len(d2[name][\"reviews_processed\"])):\n",
        "          scores3.append(round(lab2[i][0].score,3))\n",
        "          values3.append(lab2[i][0].value)\n",
        "        d2[name][\"sent_score\"] = scores3\n",
        "        d2[name][\"sent_value\"] = values3\n",
        "        d2[name] = modifies_func(d2[name])\n",
        "        \n",
        "        #update the counter \n",
        "        counter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWyzSwJ1H0EY"
      },
      "source": [
        "In this section I selected the 4th category in the AWS dataset that its size is 2740337188 [Books_01]. I Modify and use the obj to stream and loop through the gzip file of this category 100000 bytes at a time, with 100 batches. \n",
        "I got 100 batches and for each of them, I split the rows again, turned them into data frames, changed their column names and so on. I have created a dictionary that will contain all the datas so that it will be easy to access. In addition I ran on each batch the three functions I built in section 2 to fit them to the classification model and printed the number of lines in each batch as required. I added a counter variable that will update the loop so that in each iteration it will move to the next batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck396T66duRT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "1d2cf304-ace7-4f09-a06f-21ef112cfdc9"
      },
      "source": [
        "#executing the GSDlogred.partial_fit method on each processed batch\n",
        "\n",
        "#set the results\n",
        "random.seed(100)\n",
        "\n",
        "#I restart the SGDClassifier from the previous section.\n",
        "GSDlogred2 = SGDClassifier(loss='log', random_state= 4000, shuffle=False)\n",
        "\n",
        "#create empty lists of accur and average accur\n",
        "avg_accu = []\n",
        "accur = []\n",
        "\n",
        "#run on all batchs\n",
        "for name in d2.keys():\n",
        "  y2 = d2[name][\"binstar\"]  #define the y\n",
        "  mapper_fit = mapper.fit(d2[name]) #use the provided mapper function\n",
        "  x2 = pd.DataFrame(mapper.transform(d2[name])) \n",
        "  \n",
        "  #create a x_train,x_test,y_train,y_test random split of the final_df and the target binstar for each batch\n",
        "  X_tra2, X_tes2, y_tra2, y_tes2 = train_test_split(x2 , y2, test_size = 0.20)\n",
        "  \n",
        "  #normalize the data  for each batch\n",
        "  X_tes2 = Normalizer().fit_transform(X_tes2) \n",
        "  X_tra2 = Normalizer().fit_transform(X_tra2) \n",
        "\n",
        "  #preforme the GSDlogred.partial_fit methon on each batch\n",
        "  GSD_model2 = GSDlogred2.partial_fit(X_tra2,y_tra2,classes=np.unique(y_tra2))\n",
        "  accur.append(GSD_model2.score(X_tes2,y_tes2)) #compute the accur\n",
        "  avg_accu.append(sum(accur)/len(accur)) #compute the average accure of all accure until now\n",
        "\n",
        "accur_data = pd.DataFrame(accur, index= d2.keys(),columns = [\"Average test accuracy\"] )\n",
        "display(round(accur_data.transpose(),3)) #show results\n",
        "\n",
        "#show the results Average test accuracy in plot\n",
        "fig,ax = plt.subplots()\n",
        "plt.scatter(range(101),accur)\n",
        "ax.set_xlabel(\"100 Batchs\",fontsize=14)\n",
        "ax.set_ylabel(\"Test accuracy\",fontsize=14)\n",
        "ax.set_title('Test accuracy for each batchs',fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>df0</th>\n",
              "      <th>df1</th>\n",
              "      <th>df2</th>\n",
              "      <th>df3</th>\n",
              "      <th>df4</th>\n",
              "      <th>df5</th>\n",
              "      <th>df6</th>\n",
              "      <th>df7</th>\n",
              "      <th>df8</th>\n",
              "      <th>df9</th>\n",
              "      <th>df10</th>\n",
              "      <th>df11</th>\n",
              "      <th>df12</th>\n",
              "      <th>df13</th>\n",
              "      <th>df14</th>\n",
              "      <th>df15</th>\n",
              "      <th>df16</th>\n",
              "      <th>df17</th>\n",
              "      <th>df18</th>\n",
              "      <th>df19</th>\n",
              "      <th>df20</th>\n",
              "      <th>df21</th>\n",
              "      <th>df22</th>\n",
              "      <th>df23</th>\n",
              "      <th>df24</th>\n",
              "      <th>df25</th>\n",
              "      <th>df26</th>\n",
              "      <th>df27</th>\n",
              "      <th>df28</th>\n",
              "      <th>df29</th>\n",
              "      <th>df30</th>\n",
              "      <th>df31</th>\n",
              "      <th>df32</th>\n",
              "      <th>df33</th>\n",
              "      <th>df34</th>\n",
              "      <th>df35</th>\n",
              "      <th>df36</th>\n",
              "      <th>df37</th>\n",
              "      <th>df38</th>\n",
              "      <th>df39</th>\n",
              "      <th>...</th>\n",
              "      <th>df61</th>\n",
              "      <th>df62</th>\n",
              "      <th>df63</th>\n",
              "      <th>df64</th>\n",
              "      <th>df65</th>\n",
              "      <th>df66</th>\n",
              "      <th>df67</th>\n",
              "      <th>df68</th>\n",
              "      <th>df69</th>\n",
              "      <th>df70</th>\n",
              "      <th>df71</th>\n",
              "      <th>df72</th>\n",
              "      <th>df73</th>\n",
              "      <th>df74</th>\n",
              "      <th>df75</th>\n",
              "      <th>df76</th>\n",
              "      <th>df77</th>\n",
              "      <th>df78</th>\n",
              "      <th>df79</th>\n",
              "      <th>df80</th>\n",
              "      <th>df81</th>\n",
              "      <th>df82</th>\n",
              "      <th>df83</th>\n",
              "      <th>df84</th>\n",
              "      <th>df85</th>\n",
              "      <th>df86</th>\n",
              "      <th>df87</th>\n",
              "      <th>df88</th>\n",
              "      <th>df89</th>\n",
              "      <th>df90</th>\n",
              "      <th>df91</th>\n",
              "      <th>df92</th>\n",
              "      <th>df93</th>\n",
              "      <th>df94</th>\n",
              "      <th>df95</th>\n",
              "      <th>df96</th>\n",
              "      <th>df97</th>\n",
              "      <th>df98</th>\n",
              "      <th>df99</th>\n",
              "      <th>df100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Average test accuracy</th>\n",
              "      <td>0.867</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.882</td>\n",
              "      <td>0.969</td>\n",
              "      <td>0.765</td>\n",
              "      <td>0.914</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.805</td>\n",
              "      <td>0.907</td>\n",
              "      <td>0.909</td>\n",
              "      <td>0.975</td>\n",
              "      <td>0.929</td>\n",
              "      <td>0.897</td>\n",
              "      <td>0.921</td>\n",
              "      <td>0.977</td>\n",
              "      <td>0.714</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.933</td>\n",
              "      <td>0.975</td>\n",
              "      <td>0.968</td>\n",
              "      <td>0.929</td>\n",
              "      <td>0.957</td>\n",
              "      <td>0.903</td>\n",
              "      <td>0.946</td>\n",
              "      <td>0.976</td>\n",
              "      <td>0.909</td>\n",
              "      <td>0.909</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.886</td>\n",
              "      <td>0.818</td>\n",
              "      <td>0.848</td>\n",
              "      <td>0.921</td>\n",
              "      <td>0.932</td>\n",
              "      <td>0.967</td>\n",
              "      <td>0.905</td>\n",
              "      <td>0.974</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.971</td>\n",
              "      <td>...</td>\n",
              "      <td>0.953</td>\n",
              "      <td>0.944</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.977</td>\n",
              "      <td>0.921</td>\n",
              "      <td>0.957</td>\n",
              "      <td>0.949</td>\n",
              "      <td>0.971</td>\n",
              "      <td>0.897</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.897</td>\n",
              "      <td>0.892</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.898</td>\n",
              "      <td>0.912</td>\n",
              "      <td>0.947</td>\n",
              "      <td>0.946</td>\n",
              "      <td>0.865</td>\n",
              "      <td>0.895</td>\n",
              "      <td>0.973</td>\n",
              "      <td>0.912</td>\n",
              "      <td>0.907</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.895</td>\n",
              "      <td>0.939</td>\n",
              "      <td>0.917</td>\n",
              "      <td>0.821</td>\n",
              "      <td>0.846</td>\n",
              "      <td>0.881</td>\n",
              "      <td>0.923</td>\n",
              "      <td>0.951</td>\n",
              "      <td>0.976</td>\n",
              "      <td>0.902</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.853</td>\n",
              "      <td>0.923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 101 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         df0    df1    df2    df3  ...  df97  df98   df99  df100\n",
              "Average test accuracy  0.867  0.925  0.882  0.969  ...   1.0   1.0  0.853  0.923\n",
              "\n",
              "[1 rows x 101 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXWd0LgeIf5i"
      },
      "source": [
        "I ran the SGDClassifier classification model on all batches. I first initialized the container (so that it would not remember what it learned in the previous section). I went through a loop on all the batches (data) and ran the mapping function provided to us. I divided the batchs into train and test, normalized and ran the partial_fit method. Its accuracy and I also calculated in each iteration the average accuracy index of all the models that have been so far.\n",
        "\n",
        "I presented the accuracy indices of all the models in the list and also in the graph. It can be seen that the values ​​of the accuracy indices are relatively uniformly distributed throughout the batchs And concentrate mainly on values ​​between 0.8 -1 with no visible trend.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy7HaYT3c8kc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "a51e8389-6b0d-4d76-c89b-500dbec4b83b"
      },
      "source": [
        "#I choose to show the average accuracy  over all batches so far in plot\n",
        "fig,ax = plt.subplots()\n",
        "plt.plot(avg_accu)\n",
        "ax.set_xlabel(\"Batchs\",fontsize=14)\n",
        "ax.set_ylabel(\"Test accuracy\",fontsize=14)\n",
        "ax.set_title('The average test accuracy over all batches',fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVVURu-oEls0"
      },
      "source": [
        "**Do you see an improvement as you use more and more batches?**\n",
        "\n",
        "I chose to report the average test accuracy over all batches **so far**\n",
        "Using a graph because I think that way we can see the results most clearly. When we see the graph showing the average test accuracy over all batches **so far** we can clearly see that the accuracy improves on average as the amount of batchs increases. At the beginning there are some jumps but an increase as trend but after 40 batch we can se that the average index converges to 0.92 area. That is, we can learn that although we can not see improvement when looking at the accuracy index of each batch individually, it is possible to conclude that the model improves on average its accuracy the more times it is operated (meaning the more batchs we run it on).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtqHLksmulek"
      },
      "source": [
        "**4.(d) [6 pt] Open Question** How can you improve the classifier? Suggest and implement a way to train a classifier such that the test error on the category you picked in question **1.(d)**  will improve compared to all previous results for this test set. \n",
        "\n",
        "You can be creative: use additional data, fit additional models (e.g. nonlinear), change the training algorithm, etc. \n",
        "\n",
        "Report the running time and the test accuracy of your algorithm \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwtqX74Usw8L"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPZv943mR_wm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fbeac75-2cb8-49cc-a8f8-9afd0448e5d1"
      },
      "source": [
        "#first implement\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "s = time.time() #start time\n",
        "\n",
        "#Create a RandomForest Classifier unnormelized train and test\n",
        "clf=RandomForestClassifier(n_estimators=400).fit(X_train_not_norm, y_train_not_norm)\n",
        "\n",
        "#compute accuracy of train and test\n",
        "accuracy_forest_train = clf.score(X_train_not_norm, y_train_not_norm)\n",
        "accuracy_forest_test = clf.score(X_test_not_norm, y_test_not_norm)\n",
        "\n",
        "e = time.time() #end time\n",
        "t = e-s\n",
        "\n",
        "print(\"Random Forest Classifier model - train accuracy:\", round(accuracy_forest_train,3))\n",
        "print(\"Random Forest Classifier model - test accuracy:\", round(accuracy_forest_test,3))\n",
        "print(\"The running time is: \", round(t,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier model - train accuracy: 0.997\n",
            "Random Forest Classifier model - test accuracy: 0.908\n",
            "The running time is:  181.709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-smR3gCaHyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea3c05ff-6791-405f-9142-1200e9e592a9"
      },
      "source": [
        "#second implement\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "s2 = time.time()  #start time\n",
        "\n",
        "#Create a Gradient Boosting Classifier use unnormelized train and test\n",
        "clf2=GradientBoostingClassifier(n_estimators=100).fit(X_train_not_norm, y_train_not_norm)\n",
        "\n",
        "#compute accuracy of train and test \n",
        "accuracy_forest_Boosting_train = clf2.score(X_train_not_norm, y_train_not_norm)\n",
        "accuracy_forest_Boosting_test = clf2.score(X_test_not_norm, y_test_not_norm)\n",
        "\n",
        "e2 = time.time()  #end time\n",
        "t2 = e2 - s2\n",
        "\n",
        "print(\"Gradient Boosting Classifier model - train accuracy:\", round(accuracy_forest_Boosting_train,3))\n",
        "print(\"Gradient Boosting Classifier model - test accuracy:\", round(accuracy_forest_Boosting_test,3))\n",
        "print(\"The running time is: \", round(t2,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Classifier model - train accuracy: 0.903\n",
            "Gradient Boosting Classifier model - test accuracy: 0.901\n",
            "The running time is:  88.802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DZ-ymIcIZve"
      },
      "source": [
        "In order to improve the Classifier I have tried several types of classifications to find the best one. For example, regression RIDGE, LASSO, KNN and etc. I decided to chose two algorithms: Random Forest Classifier and Gradient Boosting Classifier. The reason I chose these two algorithms is that it seems that despite all the changes we made during the various sections on the data, we did not seem to be able to improve the accuracy of the model significantly (and even in some cases actually lower the accuracy index). So I decided to choose another family of classification algorithms to try to improve the model.\n",
        "\n",
        "Random forest is an ensemble learning method for classification or regression. The algorithem construct a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees.\n",
        "\n",
        "Gradient boosting is a machine learning technique for regression or classification, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion, and it generalizes them by allowing optimization of an arbitrary differentiable loss function.\n",
        "\n",
        "Both algorithms are based on division into decision trees where each has its advantages and disadvantages. I chose to compare these two algorithms because they have similar characteristics and because both yielded the best Classification results for the data. I worked with both algorithms in a similar way. Since the Random Forest and the Gradient boosting algorithms does not based on distances I thought there was no need to normalize the data (to check myself, I tried to normalize it and the result did not improve). \n",
        "\n",
        "At first I chose to create 100 trees in Random forest algorithms but I got too big difference between the train accuracy index and the test accuracy index But his running time was very short (about 20-30). Following these results I realized that it is necessary to build more trees to evoid over-fitting and to improve the result. I decided to make some attempts of choosing more  trees (to try to reduce the overfiting) and finally chose 400 trees for Random forest (This number of trees improved the result and reduced a bit the over-fitting). But when I added more trees it can be seen that the runtime increased much, even more than the runtime of the second algorithm. Conversely when I selected 100 trees of the Gradient boosting algorithm, there did not appear to be over-fitting according to the results at all (as you can see in the train results). And also run time is shorter than in the Random Forest algorithm.\n",
        "\n",
        "\n",
        "In conclusion, each of the methods has advantages and disadvantages and both of them  manages to raise the accuracy index not bad.  \n",
        "But in this case it can be seen that Gradient boosting algorithm Gives better results, both in terms of runtime and for over-fitting and still manages to improve the accuracy. Conversely the Random forest algorithms still does over fitting and its runing time is higher, therefor I choose Gradient boosting classifier to improve the classifier.\n"
      ]
    }
  ]
}